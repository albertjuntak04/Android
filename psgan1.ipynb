{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "psgan1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1wTwuN589Z4N6a_tRM46ywI2pY8yVMKCt",
      "authorship_tag": "ABX9TyOJ8FtP24KWDKpwPsxOTPUO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertjuntak04/Android/blob/master/psgan1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "882LMJCB2ABq",
        "outputId": "c804ef24-d660-441c-8b0b-da10ca197a58"
      },
      "source": [
        "! wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "! chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "! bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-16 04:42:35--  https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85055499 (81M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py37_4.8.2-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py37_4.8 100%[===================>]  81.12M   148MB/s    in 0.5s    \n",
            "\n",
            "2020-12-16 04:42:36 (148 MB/s) - ‘Miniconda3-py37_4.8.2-Linux-x86_64.sh’ saved [85055499/85055499]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.3.0=py37_0\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2019.11.28=py37_0\n",
            "    - cffi==1.14.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.8.2=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_0\n",
            "    - openssl==1.1.1d=h7b6447c_4\n",
            "    - pip==20.0.2=py37_1\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.6=h0371630_2\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_1\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==45.2.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.42.1=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.3.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.11.28-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.2-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_4\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_1\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.6-h0371630_2\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_1\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-45.2.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.42.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9siaAAF2vPm",
        "outputId": "9fa0bb4d-d8fd-4e15-dda7-4fa70cb997f6"
      },
      "source": [
        "! conda install -c rdkit rdkit -y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    bzip2-1.0.8                |       h7b6447c_0          78 KB\n",
            "    ca-certificates-2020.12.8  |       h06a4308_0         121 KB\n",
            "    cairo-1.14.12              |       h8948797_3         906 KB\n",
            "    certifi-2020.12.5          |   py37h06a4308_0         141 KB\n",
            "    conda-4.9.2                |   py37h06a4308_0         2.9 MB\n",
            "    fontconfig-2.13.0          |       h9420a91_0         227 KB\n",
            "    freetype-2.10.4            |       h5ab3b9f_0         596 KB\n",
            "    glib-2.66.1                |       h92f7085_0         2.9 MB\n",
            "    icu-58.2                   |       he6710b0_3        10.5 MB\n",
            "    intel-openmp-2020.2        |              254         786 KB\n",
            "    jpeg-9b                    |       h024ee3a_2         214 KB\n",
            "    lcms2-2.11                 |       h396b838_0         307 KB\n",
            "    libboost-1.73.0            |      hf484d3e_11        13.9 MB\n",
            "    libffi-3.3                 |       he6710b0_2          50 KB\n",
            "    libpng-1.6.37              |       hbc83047_0         278 KB\n",
            "    libtiff-4.1.0              |       h2733197_1         449 KB\n",
            "    libuuid-1.0.3              |       h1bed415_2          15 KB\n",
            "    libxcb-1.14                |       h7b6447c_0         505 KB\n",
            "    libxml2-2.9.10             |       hb55368b_3         1.2 MB\n",
            "    lz4-c-1.9.2                |       heb0550a_3         175 KB\n",
            "    mkl-2020.2                 |              256       138.3 MB\n",
            "    mkl-service-2.3.0          |   py37he8ac12f_0          52 KB\n",
            "    mkl_fft-1.2.0              |   py37h23d657b_0         148 KB\n",
            "    mkl_random-1.1.1           |   py37h0573a6f_0         322 KB\n",
            "    numpy-1.19.2               |   py37h54aff64_0          22 KB\n",
            "    numpy-base-1.19.2          |   py37hfa32c7d_0         4.1 MB\n",
            "    olefile-0.46               |           py37_0          50 KB\n",
            "    openssl-1.1.1i             |       h27cfd23_0         2.5 MB\n",
            "    pandas-1.1.5               |   py37ha9443f7_0         8.2 MB\n",
            "    pcre-8.44                  |       he6710b0_0         212 KB\n",
            "    pillow-8.0.1               |   py37he98fc37_0         619 KB\n",
            "    pixman-0.40.0              |       h7b6447c_0         370 KB\n",
            "    py-boost-1.73.0            |  py37h04863e7_11         202 KB\n",
            "    python-dateutil-2.8.1      |             py_0         215 KB\n",
            "    pytz-2020.4                |     pyhd3eb1b0_0         180 KB\n",
            "    rdkit-2020.09.1.0          |   py37hd50e099_1        25.8 MB  rdkit\n",
            "    xz-5.2.5                   |       h7b6447c_0         341 KB\n",
            "    zstd-1.4.5                 |       h9ceee32_0         619 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       218.3 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
            "  cairo              pkgs/main/linux-64::cairo-1.14.12-h8948797_3\n",
            "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.0-h9420a91_0\n",
            "  freetype           pkgs/main/linux-64::freetype-2.10.4-h5ab3b9f_0\n",
            "  glib               pkgs/main/linux-64::glib-2.66.1-h92f7085_0\n",
            "  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2020.2-254\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9b-h024ee3a_2\n",
            "  lcms2              pkgs/main/linux-64::lcms2-2.11-h396b838_0\n",
            "  libboost           pkgs/main/linux-64::libboost-1.73.0-hf484d3e_11\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.1.0-h2733197_1\n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2\n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.14-h7b6447c_0\n",
            "  libxml2            pkgs/main/linux-64::libxml2-2.9.10-hb55368b_3\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.2-heb0550a_3\n",
            "  mkl                pkgs/main/linux-64::mkl-2020.2-256\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py37he8ac12f_0\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.2.0-py37h23d657b_0\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.1-py37h0573a6f_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.19.2-py37h54aff64_0\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.19.2-py37hfa32c7d_0\n",
            "  olefile            pkgs/main/linux-64::olefile-0.46-py37_0\n",
            "  pandas             pkgs/main/linux-64::pandas-1.1.5-py37ha9443f7_0\n",
            "  pcre               pkgs/main/linux-64::pcre-8.44-he6710b0_0\n",
            "  pillow             pkgs/main/linux-64::pillow-8.0.1-py37he98fc37_0\n",
            "  pixman             pkgs/main/linux-64::pixman-0.40.0-h7b6447c_0\n",
            "  py-boost           pkgs/main/linux-64::py-boost-1.73.0-py37h04863e7_11\n",
            "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               pkgs/main/noarch::pytz-2020.4-pyhd3eb1b0_0\n",
            "  rdkit              rdkit/linux-64::rdkit-2020.09.1.0-py37hd50e099_1\n",
            "  zstd               pkgs/main/linux-64::zstd-1.4.5-h9ceee32_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                                2020.1.1-0 --> 2020.12.8-h06a4308_0\n",
            "  certifi                                 2019.11.28-py37_0 --> 2020.12.5-py37h06a4308_0\n",
            "  conda                                        4.8.2-py37_0 --> 4.9.2-py37h06a4308_0\n",
            "  libffi                                   3.2.1-hd88cf55_4 --> 3.3-he6710b0_2\n",
            "  openssl                                 1.1.1d-h7b6447c_4 --> 1.1.1i-h27cfd23_0\n",
            "  xz                                       5.2.4-h14c3975_4 --> 5.2.5-h7b6447c_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "libtiff-4.1.0        | 449 KB    | : 100% 1.0/1 [00:00<00:00,  5.03it/s]                 \n",
            "fontconfig-2.13.0    | 227 KB    | : 100% 1.0/1 [00:00<00:00, 14.09it/s]\n",
            "libuuid-1.0.3        | 15 KB     | : 100% 1.0/1 [00:00<00:00, 18.90it/s]\n",
            "zstd-1.4.5           | 619 KB    | : 100% 1.0/1 [00:00<00:00, 12.73it/s]\n",
            "lz4-c-1.9.2          | 175 KB    | : 100% 1.0/1 [00:00<00:00, 15.26it/s]\n",
            "python-dateutil-2.8. | 215 KB    | : 100% 1.0/1 [00:00<00:00, 18.20it/s]\n",
            "libffi-3.3           | 50 KB     | : 100% 1.0/1 [00:00<00:00, 19.43it/s]\n",
            "numpy-1.19.2         | 22 KB     | : 100% 1.0/1 [00:00<00:00, 19.75it/s]\n",
            "mkl-service-2.3.0    | 52 KB     | : 100% 1.0/1 [00:00<00:00, 18.27it/s]\n",
            "xz-5.2.5             | 341 KB    | : 100% 1.0/1 [00:00<00:00, 15.62it/s]\n",
            "pillow-8.0.1         | 619 KB    | : 100% 1.0/1 [00:00<00:00, 10.60it/s]\n",
            "pcre-8.44            | 212 KB    | : 100% 1.0/1 [00:00<00:00, 17.39it/s]\n",
            "numpy-base-1.19.2    | 4.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.74it/s]               \n",
            "conda-4.9.2          | 2.9 MB    | : 100% 1.0/1 [00:00<00:00,  6.79it/s]\n",
            "mkl_random-1.1.1     | 322 KB    | : 100% 1.0/1 [00:00<00:00, 18.45it/s]\n",
            "openssl-1.1.1i       | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  8.53it/s]\n",
            "mkl_fft-1.2.0        | 148 KB    | : 100% 1.0/1 [00:00<00:00, 17.08it/s]\n",
            "libxml2-2.9.10       | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  9.02it/s]\n",
            "icu-58.2             | 10.5 MB   | : 100% 1.0/1 [00:00<00:00,  1.95it/s]               \n",
            "olefile-0.46         | 50 KB     | : 100% 1.0/1 [00:00<00:00, 19.12it/s]\n",
            "mkl-2020.2           | 138.3 MB  | : 100% 1.0/1 [00:04<00:00,  4.99s/it]               \n",
            "blas-1.0             | 6 KB      | : 100% 1.0/1 [00:00<00:00, 17.39it/s]\n",
            "pixman-0.40.0        | 370 KB    | : 100% 1.0/1 [00:00<00:00, 15.27it/s]\n",
            "certifi-2020.12.5    | 141 KB    | : 100% 1.0/1 [00:00<00:00, 17.59it/s]\n",
            "cairo-1.14.12        | 906 KB    | : 100% 1.0/1 [00:00<00:00,  9.90it/s]\n",
            "py-boost-1.73.0      | 202 KB    | : 100% 1.0/1 [00:00<00:00, 13.51it/s]\n",
            "intel-openmp-2020.2  | 786 KB    | : 100% 1.0/1 [00:00<00:00, 11.89it/s]\n",
            "bzip2-1.0.8          | 78 KB     | : 100% 1.0/1 [00:00<00:00, 14.45it/s]\n",
            "ca-certificates-2020 | 121 KB    | : 100% 1.0/1 [00:00<00:00, 18.96it/s]\n",
            "libpng-1.6.37        | 278 KB    | : 100% 1.0/1 [00:00<00:00, 13.65it/s]\n",
            "pytz-2020.4          | 180 KB    | : 100% 1.0/1 [00:00<00:00, 11.02it/s]\n",
            "libxcb-1.14          | 505 KB    | : 100% 1.0/1 [00:00<00:00, 12.41it/s]\n",
            "freetype-2.10.4      | 596 KB    | : 100% 1.0/1 [00:00<00:00, 13.86it/s]\n",
            "jpeg-9b              | 214 KB    | : 100% 1.0/1 [00:00<00:00, 18.46it/s]\n",
            "pandas-1.1.5         | 8.2 MB    | : 100% 1.0/1 [00:00<00:00,  2.02it/s]              \n",
            "glib-2.66.1          | 2.9 MB    | : 100% 1.0/1 [00:00<00:00,  4.14it/s]               \n",
            "libboost-1.73.0      | 13.9 MB   | : 100% 1.0/1 [00:02<00:00,  1.96s/it]               \n",
            "rdkit-2020.09.1.0    | 25.8 MB   | : 100% 1.0/1 [00:06<00:00,  6.15s/it]\n",
            "lcms2-2.11           | 307 KB    | : 100% 1.0/1 [00:00<00:00, 14.92it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK4rGA8929z9",
        "outputId": "8ec5b2b7-eec0-4b48-abfb-dbda0c11b1b4"
      },
      "source": [
        "! conda install -c rdkit rdkit -y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "MnFJQaZ43R8s",
        "outputId": "d33129d0-6ca4-4e62-88ff-048469edf103"
      },
      "source": [
        "python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a4637bbefc43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpython\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mfLpBt-3syL",
        "outputId": "66350fa8-8943-484c-caa9-d170bb2624c8"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT0d2m0M3yso"
      },
      "source": [
        "# data_io\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL.Image import FLIP_LEFT_RIGHT\n",
        "\n",
        "\n",
        "def image_to_tensor(img):\n",
        "    '''\n",
        "    convert image to Theano/Lasagne 3-tensor format;\n",
        "    changes channel dimension to be in the first position and rescales from [0,255] to [-1,1]\n",
        "    '''\n",
        "    tensor = np.array(img).transpose( (2,0,1) )\n",
        "    tensor = (tensor / 255.)*2 - 1.\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "    '''\n",
        "    convert 3-tensor to image;\n",
        "    changes channel to be last and rescales from [-1, 1] to [0, 255]\n",
        "    '''\n",
        "    img = np.array(tensor).transpose( (1,2,0) )\n",
        "    img = (img + 1.)/2 * 255.\n",
        "    return np.uint8(img)\n",
        "    \n",
        "\n",
        "def get_texture_iter(folder, npx=128, batch_size=64, \\\n",
        "                     filter=None, mirror=True):\n",
        "    '''\n",
        "    @param folder       iterate of pictures from this folder\n",
        "    @param npx          size of patches to extract\n",
        "    @param n_batches    number of batches to yield - if None, it yields forever\n",
        "    @param mirror       if True the images get augmented by left-right mirroring\n",
        "    @return a batch of image patches fo size npx x npx, with values in [0,1]\n",
        "    '''\n",
        "    HW    = npx\n",
        "    imTex = []\n",
        "    files = os.listdir(folder)\n",
        "    for f in files:\n",
        "        name = folder + f\n",
        "        try:\n",
        "            img = Image.open(name)\n",
        "            imTex += [image_to_tensor(img)]\n",
        "            if mirror:\n",
        "                img = img.transpose(FLIP_LEFT_RIGHT)\n",
        "                imTex += [image_to_tensor(img)]\n",
        "        except:\n",
        "            print (\"Image \", name, \" failed to load!\")\n",
        "\n",
        "    while True:\n",
        "        data=np.zeros((batch_size,3,npx,npx))                   # NOTE: assumes 3 channels!\n",
        "        for i in range(batch_size):\n",
        "            ir = np.random.randint(len(imTex))\n",
        "            imgBig = imTex[ir]\n",
        "            if HW < imgBig.shape[1] and HW < imgBig.shape[2]:   # sample patches\n",
        "                h = np.random.randint(imgBig.shape[1] - HW)\n",
        "                w = np.random.randint(imgBig.shape[2] - HW)\n",
        "                img = imgBig[:, h:h + HW, w:w + HW]\n",
        "            else:                                               # whole input texture\n",
        "                img = imgBig\n",
        "            data[i] = img\n",
        "\n",
        "        yield data\n",
        "\n",
        "\n",
        "def save_tensor(tensor, filename):\n",
        "    '''\n",
        "    save a 3-tensor (channel, x, y) to image file\n",
        "    '''\n",
        "    img = tensor_to_image(tensor)\n",
        "    img = Image.fromarray(img)\n",
        "    img.save(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXo3Niq435nV"
      },
      "source": [
        "# tools\n",
        "# -*- coding: utf-8 -*-\n",
        "import sys, os\n",
        "from time import time\n",
        "\n",
        "\n",
        "def create_dir(folder):\n",
        "    '''\n",
        "    creates a folder, if necessary\n",
        "    '''\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "\n",
        "class TimePrint(object):\n",
        "    '''\n",
        "    Simple convenience class to print who long it takes between successive calls to its __init__ function.\n",
        "    Usage example:\n",
        "        TimePrint(\"some text\")          -- simply prints \"some text\"\n",
        "        <do some stuff here>\n",
        "        TimePrint(\"some other text \")   -- prints \"some other text (took ?s)\", where ? is the time passed since TimePrint(\"some text\") was called\n",
        "    '''\n",
        "    t_last = None\n",
        "\n",
        "    def __init__(self, text):\n",
        "        TimePrint.p(text)\n",
        "\n",
        "    @classmethod\n",
        "    def p(cls, text):\n",
        "        t = time()\n",
        "        print (text),\n",
        "        if cls.t_last!=None:\n",
        "            print (\" (took \", t-cls.t_last, \"s)\")\n",
        "        cls.t_last = t\n",
        "        sys.stdout.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBjMxndN38G9"
      },
      "source": [
        "# config\n",
        "import os\n",
        "# from tools import create_dir\n",
        "# from data_io import get_texture_iter\n",
        "\n",
        "create_dir('drive/MyDrive/samples')               # create, if necessary, for the output samples \n",
        "create_dir('drive/MyDrive/models') \n",
        "# home        = os.path.expanduser(\"~\")\n",
        "\n",
        "\n",
        "def zx_to_npx(zx, depth):\n",
        "    '''\n",
        "    calculates the size of the output image given a stack of 'same' padded\n",
        "    convolutional layers with size depth, and the size of the input field zx\n",
        "    '''\n",
        "    # note: in theano we'd have zx*2**depth\n",
        "    return (zx - 1)*2**depth + 1\n",
        "\n",
        "\n",
        "class Config(object):\n",
        "    '''\n",
        "    wraps all configuration parameters in 'static' variables -- these are not serialized!!\n",
        "    '''    \n",
        "    #optimization constants\n",
        "    lr          = 0.0002                # learning rate of adam\n",
        "    b1          = 0.5                   # momentum term of adam\n",
        "    l2_fac      = 1e-8                  # L2 weight regularization factor\n",
        "    epoch_count = 10                   #how many epochs to do globally    \n",
        "    k           = 1                     # number of D updates vs G updates\n",
        "    batch_size  = 8\n",
        "    epoch_iters =batch_size * 500      #steps inside one epoch \n",
        "                 \n",
        "    ##constructor to define serializable variables, serialized when dumping model\n",
        "    def __init__(self):    \n",
        "        ##\n",
        "        # sampling parameters    \n",
        "        self.nz_local = 30    \n",
        "        self.nz_global = 60                 # num of global Z dimensions\n",
        "        self.nz_periodic = 3                    # num of global Z dimensions\n",
        "        self.nz_periodic_MLPnodes = 50          # the MLP gate for the neural network\n",
        "        self.nz          = self.nz_local+self.nz_global+self.nz_periodic*2                   # num of dim for Z at each field position, sum of local, global, periodic dimensions\n",
        "        self.periodic_affine = False            # if True planar waves sum x,y sinusoids, else axes aligned sinusoids x or y \n",
        "        self.zx          = 2                    # number of spatial dimensions in Z (jumlah dimensi spasial di Z)\n",
        "        self.zx_sample   = 32                   # size of the spatial dimension in Z for producing the samples    \n",
        "        self.zx_sample_quilt = self.zx_sample/1      # how many tiles in the global dimension quilt for output sampling\n",
        "\n",
        "        ##\n",
        "        # network parameters\n",
        "        self.nc          = 3                     # number of channels in input X (i.e. r,g,b)\n",
        "        self.gen_ks      = ([(5,5)] * 5)[::-1]   # kernel sizes on each layer - should be odd numbers for zero-padding stuff\n",
        "        self.dis_ks      = [(5,5)] * 5           # kernel sizes on each layer - should be odd numbers for zero-padding stuff\n",
        "        self.gen_ls      = len(self.gen_ks)           # num of layers in the generative network\n",
        "        self.dis_ls      = len(self.dis_ks)           # num of layers in the discriminative network\n",
        "        self.gen_fn      = [self.nc]+[2**(n+6) for n in range(self.gen_ls-1)]  # generative number of filters\n",
        "        self.gen_fn      = self.gen_fn[::-1]\n",
        "        self.dis_fn      = [2**(n+6) for n in range(self.dis_ls-1)]+[1]   # discriminative number of filters        \n",
        "        self.npx         = zx_to_npx(self.zx, self.gen_ls) # num of pixels width/height of images in X\n",
        "        \n",
        "        ##input texture folder\n",
        "        self.sub_name    = \"ulos1\"\n",
        "        self.texture_dir = \"drive/MyDrive/data/\"\n",
        "        self.save_name   = self.sub_name+ \"_filters%d_npx%d_%dgL_%ddL_%dGlobal_%dPeriodic_%sAffine_%dLocal\" % (self.dis_fn[0],self.npx,self.gen_ls, self.dis_ls,self.nz_global,self.nz_periodic,self.periodic_affine ,self.nz_local)\n",
        "        self.load_name   = None                  # if None, initializing network from scratch\n",
        "        \n",
        "        \n",
        "           \n",
        "    ## gives back the correct data iterator given class variables -- this way we avoid the python restriction not to pickle iterator objects\n",
        "    def data_iter(self):\n",
        "        return get_texture_iter(self.texture_dir, npx=self.npx, mirror=False, batch_size=self.batch_size)\n",
        "\n",
        "    def print_info(self):\n",
        "        ##\n",
        "        # output some information\n",
        "        print (\"Learning and generating samples from zx \", self.zx, \", which yields images of size npx \", zx_to_npx(self.zx, self.gen_ls)) \n",
        "        print (\"Producing samples from zx_sample \", self.zx_sample, \", which yields images of size npx \", zx_to_npx(self.zx_sample, self.gen_ls)) \n",
        "        print (\"Saving samples and model data to file \",self.save_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twiaA4xh3_rc"
      },
      "source": [
        "#psgan\n",
        "import lasagne\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "import sys, os\n",
        "import joblib\n",
        "\n",
        "# from config import Config\n",
        "# from tools import TimePrint\n",
        "# from data_io import get_texture_iter, save_tensor\n",
        "\n",
        "\n",
        "##\n",
        "# define shortcuts for lasagne functions\n",
        "relu        = lasagne.nonlinearities.rectify\n",
        "lrelu       = lasagne.nonlinearities.LeakyRectify(0.2)\n",
        "tanh        = lasagne.nonlinearities.tanh\n",
        "sigmoid     = lasagne.nonlinearities.sigmoid\n",
        "conv        = lambda incoming, num_filters, filter_size, W, b, nonlinearity: \\\n",
        "                lasagne.layers.Conv2DLayer(incoming, num_filters, filter_size, stride=(2,2), pad='same', W=W, b=b, flip_filters=True, nonlinearity=nonlinearity)\n",
        "tconv       = lambda incoming, num_filters, filter_size, W, nonlinearity: lasagne.layers.TransposedConv2DLayer(incoming, num_filters, filter_size, stride=(2,2), crop='same', W=W, nonlinearity=nonlinearity)\n",
        "batchnorm   = lasagne.layers.batch_norm\n",
        "\n",
        "# bias and weight initializations\n",
        "w_init      = lasagne.init.Normal(std=0.02)\n",
        "b_init      = lasagne.init.Constant(val=0.0)\n",
        "g_init      = lasagne.init.Normal(mean=1.,std=0.02)\n",
        "\n",
        "\n",
        "def sharedX(X, dtype=theano.config.floatX, name=None):\n",
        "    return theano.shared(np.asarray(X, dtype=dtype), name=name)\n",
        "\n",
        "from theano.tensor.shared_randomstreams import RandomStreams\n",
        "srng = RandomStreams(seed=234)\n",
        "\n",
        "##given parameters from config, calculate the Z noise tensor\n",
        "## the tensor has channels of type Global, Local, Periodic dimensions\n",
        "## @param zx spatial size, now implemented only in square shapes\n",
        "## @param batch_size how many instances in mini-batch\n",
        "## @param zx_quilt if not None, will set  some parts of the global dims to random values in different spatial regions (tiles), else all global dim. are equal to the same vector spatially\n",
        "def sample_noise_tensor(config,batch_size,zx,zx_quilt=None):\n",
        "    Z = np.zeros((batch_size,config.nz,zx,zx))\n",
        "    Z[:,config.nz_global:config.nz_global+config.nz_local] = np.random.uniform(-1.,1., (batch_size, config.nz_local, zx, zx) )\n",
        "    \n",
        "    if zx_quilt is None:\n",
        "        Z[:,:config.nz_global] = np.random.uniform(-1.,1., (batch_size, config.nz_global, 1, 1) )\n",
        "    else:\n",
        "        for i in range(int(int(zx)/int(zx_quilt))):\n",
        "            for j in range(int(int(zx)/int(zx_quilt))):\n",
        "                Z[:,:config.nz_global,i*int(zx_quilt):(i+1)*int(zx_quilt), j*int(zx_quilt):(j+1)*int(zx_quilt)]    =np.random.uniform(-1.,1., (batch_size, config.nz_global, 1, 1) )\n",
        "   \n",
        "    \n",
        "    if config.nz_periodic > 0:\n",
        "        for i,pixel in zip(range(1,config.nz_periodic+1),np.linspace(30,130,config.nz_periodic)):\n",
        "            band =  np.pi*(0.5*i / float(config.nz_periodic) +0.5   )##initial values for numerical stability            \n",
        "            ##just horizontal and vertical coordinate indices\n",
        "            for h in range(zx):\n",
        "                Z[:, -i*2,:, h] = h * band \n",
        "            for w in range(zx):\n",
        "                Z[:, -i * 2 + 1, w] = w * band \n",
        "    return Z\n",
        "    \n",
        "class PeriodicLayer(lasagne.layers.Layer):\n",
        "\n",
        "    def __init__(self,incoming,config,wave_params):\n",
        "        self.config = config       \n",
        "        self.wave_params = wave_params\n",
        "        self.input_layer= incoming\n",
        "        self.input_shape = incoming.output_shape\n",
        "        self.get_output_kwargs = []\n",
        "        self.params = {}\n",
        "        for p in wave_params:\n",
        "            self.params[p] = set('trainable')\n",
        "\n",
        "    ##the frequency gating MLP\n",
        "    def _wave_calculation(self,Z):\n",
        "        if self.config.nz_periodic ==0:\n",
        "            return Z\n",
        "        nPeriodic = self.config.nz_periodic\n",
        "\n",
        "        if self.config.nz_global > 0:  # #MLP or directly a weight vector in case of no Global dims\n",
        "            h = T.tensordot(Z[:, :self.config.nz_global], self.wave_params[0], [1, 0]).dimshuffle(0, 3, 1, 2) + self.wave_params[1].dimshuffle('x', 0, 'x', 'x')\n",
        "            band0 = (T.tensordot(relu(h),self.wave_params[2], [1, 0]).dimshuffle(0, 3, 1, 2)) + self.wave_params[3].dimshuffle('x', 0, 'x', 'x')  # #moved relu inside\n",
        "        else:\n",
        "            band0 = self.wave_params[0].dimshuffle('x', 0, 'x', 'x')\n",
        "        \n",
        "        if self.config.periodic_affine:\n",
        "            band1 = Z[:, -nPeriodic * 2::2] * band0[:, :nPeriodic] + Z[:, -nPeriodic * 2 + 1::2] * band0[:, nPeriodic:2 * nPeriodic]\n",
        "            band2 = Z[:, -nPeriodic * 2::2] * band0[:, 2 * nPeriodic:3 * nPeriodic] + Z[:, -nPeriodic * 2 + 1::2] * band0[:, 3 * nPeriodic:]\n",
        "        else:\n",
        "            band1 = Z[:, -nPeriodic * 2::2] * band0[:, :nPeriodic] \n",
        "            band2 = Z[:, -nPeriodic * 2 + 1::2] * band0[:, 3 * nPeriodic:]\n",
        "        band = T.concatenate([band1 , band2], axis=1)       \n",
        "        ##random phase added here, use random stream generator\n",
        "        band += srng.uniform((Z.shape[0],nPeriodic * 2)).dimshuffle(0,1, 'x', 'x') *np.pi*2\n",
        "        return T.concatenate([Z[:, :-2 * nPeriodic], T.sin(band)], axis=1)\n",
        "\n",
        "    def get_output_for(self, input, **kwargs):\n",
        "        return self._wave_calculation(input)\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return (input_shape[0],input_shape[1]+self.config.nz_periodic*2,input_shape[2],input_shape[3])     \n",
        "\n",
        "\n",
        "periodic = lambda incoming,config,wave_params: PeriodicLayer(incoming,config,wave_params)\n",
        "\n",
        "##\n",
        "# network code\n",
        "class PSGAN(object):\n",
        "\n",
        "    def __init__(self, name=None):\n",
        "        '''\n",
        "        @static configuration class\n",
        "        @param name     load stored sgan model\n",
        "        '''\n",
        "        \n",
        "        if name is not None:\n",
        "            print (\"loading parameters from file:\",name)\n",
        "\n",
        "            vals =joblib.load(name)\n",
        "            self.config = vals[\"config\"]\n",
        "\n",
        "            print (\"global dimensions of loaded config file\",self.config.nz_global) \n",
        "            \n",
        "            self.dis_W = [sharedX(p) for p in vals[\"dis_W\"]]\n",
        "            self.dis_g = [sharedX(p) for p in vals[\"dis_g\"]]\n",
        "            self.dis_b = [sharedX(p) for p in vals[\"dis_b\"]]\n",
        "    \n",
        "            self.gen_W = [sharedX(p) for p in vals[\"gen_W\"]]\n",
        "            self.gen_g = [sharedX(p) for p in vals[\"gen_g\"]]\n",
        "            self.gen_b = [sharedX(p) for p in vals[\"gen_b\"]]\n",
        "\n",
        "            self.wave_params = [sharedX(p) for p in vals[\"wave_params\"]]\n",
        "            \n",
        "            ##now overwrite the static config with the correct values\n",
        "            self.config.gen_ks = []\n",
        "            self.config.gen_fn = []\n",
        "            l = len(vals[\"gen_W\"])\n",
        "            for i in range(l):\n",
        "                if i==0:\n",
        "                    self.config.nz = vals[\"gen_W\"][i].shape[0]\n",
        "                else:\n",
        "                    self.config.gen_fn +=[vals[\"gen_W\"][i].shape[0]]\n",
        "                self.config.gen_ks += [(vals[\"gen_W\"][i].shape[2],vals[\"gen_W\"][i].shape[3])]\n",
        "            self.config.nc = vals[\"gen_W\"][i].shape[1]\n",
        "            self.config.gen_fn +=[self.config.nc]\n",
        "\n",
        "            self.config.dis_ks = []\n",
        "            self.config.dis_fn = []\n",
        "            l = len(vals[\"dis_W\"])\n",
        "            for i in range(l):\n",
        "                self.config.dis_fn +=[vals[\"dis_W\"][i].shape[1]]   \n",
        "                self.config.dis_ks += [(vals[\"gen_W\"][i].shape[2],vals[\"gen_W\"][i].shape[3])]             \n",
        "\n",
        "            self._setup_gen_params(self.config.gen_ks, self.config.gen_fn)\n",
        "            self._setup_dis_params(self.config.dis_ks, self.config.dis_fn)\n",
        "        else:\n",
        "            self.config = Config()\n",
        "\n",
        "            self._setup_gen_params(self.config.gen_ks, self.config.gen_fn)\n",
        "            self._setup_dis_params(self.config.dis_ks, self.config.dis_fn)\n",
        "            ##\n",
        "            # sample the initial weights and biases\n",
        "            self._sample_initials()\n",
        "            \n",
        "            ##setup the initial MLP frequency gating weights\n",
        "            self._setup_wave_params()\n",
        "\n",
        "        self._build_sgan()\n",
        "\n",
        "\n",
        "    def save(self,name):\n",
        "        print (\"saving PSGAN parameters in file: \", name)\n",
        "        vals = {}\n",
        "        vals[\"config\"] = self.config\n",
        "        vals[\"dis_W\"] = [p.get_value() for p in self.dis_W]\n",
        "        vals[\"dis_g\"] = [p.get_value() for p in self.dis_g]\n",
        "        vals[\"dis_b\"] = [p.get_value() for p in self.dis_b]\n",
        "\n",
        "        vals[\"gen_W\"] = [p.get_value() for p in self.gen_W]\n",
        "        vals[\"gen_g\"] = [p.get_value() for p in self.gen_g]\n",
        "        vals[\"gen_b\"] = [p.get_value() for p in self.gen_b]\n",
        "\n",
        "        vals[\"wave_params\"] = [p.get_value() for p in self.wave_params]\n",
        "        \n",
        "        joblib.dump(vals,name,True)\n",
        "\n",
        "    \n",
        "    def _setup_wave_params(self):\n",
        "        '''\n",
        "        set up the parameters of the periodic dimensions, i.e. the weigts of the gating MLP\n",
        "        '''\n",
        "\n",
        "        if self.config.nz_periodic:\n",
        "            nPeriodic = self.config.nz_periodic\n",
        "            nperiodK = self.config.nz_periodic_MLPnodes\n",
        "            if self.config.nz_global >0 and nperiodK>0:##K is hidden nodes layer; MLP depending on global dimensions\n",
        "                lin1 =  sharedX( g_init.sample( (self.config.nz_global,nperiodK)))\n",
        "                bias1 = sharedX( g_init.sample( (nperiodK)))\n",
        "                lin2 =  sharedX( g_init.sample( (nperiodK,nPeriodic * 2*2)))\n",
        "                bias2 = sharedX( g_init.sample( (nPeriodic * 2*2)))\n",
        "                self.wave_params = [lin1,bias1,lin2,bias2]\n",
        "            else:##in case no global dimensions learn global wave numbers\n",
        "                bias2 = sharedX( g_init.sample( (nPeriodic * 2*2)))\n",
        "                self.wave_params = [bias2]\n",
        "            a = np.zeros(nPeriodic * 2*2)              \n",
        "            a[:nPeriodic]=1#x\n",
        "            a[nPeriodic:2*nPeriodic]=0#y\n",
        "            a[2*nPeriodic:3*nPeriodic]=0#x\n",
        "            a[3*nPeriodic:]=1#y\n",
        "            self.wave_params[-1].set_value(np.float32(a)) \n",
        "        else:\n",
        "            self.wave_params = []\n",
        "\n",
        "    def _setup_gen_params(self, gen_ks, gen_fn):\n",
        "        '''\n",
        "        set up the parameters, i.e. filter sizes per layer and depth, of the generator\n",
        "        '''\n",
        "        ## \n",
        "        # setup generator parameters and sanity checks\n",
        "        if gen_ks==None:\n",
        "            self.gen_ks = [(5,5)] * 5   # set to standard 5-layer net\n",
        "        else:\n",
        "            self.gen_ks = gen_ks\n",
        "\n",
        "       \n",
        "        self.gen_depth = len(self.gen_ks)\n",
        "\n",
        "        if gen_fn!=None:\n",
        "            assert len(gen_fn)==len(self.gen_ks), 'Layer number of filter numbers and sizes does not match.'\n",
        "            self.gen_fn = gen_fn\n",
        "        else:\n",
        "            self.gen_fn = [64] * self.gen_depth\n",
        "    \n",
        "\n",
        "    def _setup_dis_params(self, dis_ks, dis_fn):\n",
        "        '''\n",
        "        set up the parameters, i.e. filter sizes per layer and depth, of the discriminator\n",
        "        '''\n",
        "        ##\n",
        "        # setup discriminator parameters\n",
        "        if dis_ks==None:\n",
        "            self.dis_ks = [(5,5)] * 5   # set to standard 5-layer net\n",
        "        else:\n",
        "            self.dis_ks = dis_ks\n",
        "\n",
        "        self.dis_depth = len(dis_ks)\n",
        "\n",
        "        if dis_fn!=None:\n",
        "            assert len(dis_fn)==len(self.dis_ks), 'Layer number of filter numbers and sizes does not match.'\n",
        "            self.dis_fn = dis_fn\n",
        "        else:\n",
        "            self.dis_fn = [64] * self.dis_depth\n",
        "\n",
        "    def _sample_initials(self):\n",
        "        '''\n",
        "        sample the initial weights and biases and push them back to internal lists\n",
        "        '''\n",
        "        self.dis_W = []\n",
        "        self.dis_b = []\n",
        "        self.dis_g = []\n",
        "\n",
        "\n",
        "        self.dis_W.append( sharedX( w_init.sample( (self.dis_fn[0], self.config.nc, self.dis_ks[0][0], self.dis_ks[0][1]) )) )\n",
        "        for l in range(self.dis_depth-1):\n",
        "            self.dis_W.append( sharedX( w_init.sample( (self.dis_fn[l+1], self.dis_fn[l], self.dis_ks[l+1][0], self.dis_ks[l+1][1]) ) ) )\n",
        "            self.dis_b.append( sharedX( b_init.sample( (self.dis_fn[l+1]) ) ) )\n",
        "            self.dis_g.append( sharedX( g_init.sample( (self.dis_fn[l+1]) ) ) )\n",
        "    \n",
        "        self.gen_b = []\n",
        "        self.gen_g = []\n",
        "        for l in range(self.gen_depth-1):\n",
        "            self.gen_b += [sharedX( b_init.sample( (self.gen_fn[l]) ) ) ]\n",
        "            self.gen_g += [sharedX( g_init.sample( (self.gen_fn[l]) ) ) ]\n",
        "\n",
        "        self.gen_W = []\n",
        "        \n",
        "        last = self.config.nz\n",
        "        for l in range(self.gen_depth-1):\n",
        "            self.gen_W +=[sharedX( w_init.sample((last,self.gen_fn[l], self.gen_ks[l][0],self.gen_ks[l][1])))]\n",
        "            last=self.gen_fn[l]\n",
        "\n",
        "        self.gen_W +=[sharedX( w_init.sample((last,self.gen_fn[-1], self.gen_ks[-1][0],self.gen_ks[-1][1])))]   \n",
        "\n",
        "    def _spatial_generator(self, inlayer):\n",
        "        '''\n",
        "        creates a PSGAN generator network\n",
        "        @param  inlayer     Lasagne layer\n",
        "        '''\n",
        "        layers  = [inlayer]\n",
        "        layers.append(periodic(inlayer,self.config,self.wave_params))\n",
        "        for l in range(self.gen_depth-1):\n",
        "            layers.append( batchnorm(tconv(layers[-1], self.gen_fn[l], self.gen_ks[l],self.gen_W[l], nonlinearity=relu),gamma=self.gen_g[l],beta=self.gen_b[l]) )\n",
        "        output  = tconv(layers[-1], self.gen_fn[-1], self.gen_ks[-1],self.gen_W[-1] , nonlinearity=tanh)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def _spatial_discriminator(self, inlayer):\n",
        "        '''\n",
        "        creates a PSGAN discriminator network\n",
        "        @param  inlayer     Lasagne layer\n",
        "        '''\n",
        "        layers  = [inlayer]\n",
        "        layers.append( conv(layers[-1], self.dis_fn[0], self.dis_ks[0], self.dis_W[0], None, nonlinearity=lrelu) )\n",
        "        for l in range(1,self.dis_depth-1):\n",
        "            layers.append( batchnorm(conv(layers[-1], self.dis_fn[l], self.dis_ks[l], self.dis_W[l],None,nonlinearity=lrelu),gamma=self.dis_g[l-1],beta=self.dis_b[l-1]) )\n",
        "        output = conv(layers[-1], self.dis_fn[-1], self.dis_ks[-1], self.dis_W[-1], None, nonlinearity=sigmoid)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def _build_sgan(self):\n",
        "        ##\n",
        "        # network\n",
        "        Z               = lasagne.layers.InputLayer((None,self.config.nz,None,None))   # leave batch_size and shape unspecified for now\n",
        "        X               = lasagne.layers.InputLayer((self.config.batch_size,self.config.nc,self.config.npx,self.config.npx))   # leave batch_size and shape unspecified for now\n",
        "\n",
        "        gen_X           = self._spatial_generator(Z)\n",
        "        d_real          = self._spatial_discriminator(X)\n",
        "        d_fake          = self._spatial_discriminator(gen_X)\n",
        "\n",
        "        prediction_gen  = lasagne.layers.get_output(gen_X)\n",
        "        prediction_real = lasagne.layers.get_output(d_real)\n",
        "        prediction_fake = lasagne.layers.get_output(d_fake)\n",
        "\n",
        "        params_g        = lasagne.layers.get_all_params(gen_X, trainable=True)\n",
        "        params_d        = lasagne.layers.get_all_params(d_real, trainable=True)\n",
        "\n",
        "        ##\n",
        "        # objectives\n",
        "        l2_gen          = lasagne.regularization.regularize_network_params(gen_X, lasagne.regularization.l2)\n",
        "        l2_dis          = lasagne.regularization.regularize_network_params(d_real, lasagne.regularization.l2)\n",
        "\n",
        "        obj_d= -T.mean(T.log(1-prediction_fake)) - T.mean( T.log(prediction_real)) + self.config.l2_fac * l2_dis\n",
        "        obj_g= -T.mean(T.log(prediction_fake)) + self.config.l2_fac * l2_gen\n",
        "\n",
        "        ##\n",
        "        # updates\n",
        "        updates_d       = lasagne.updates.adam(obj_d, params_d, self.config.lr, self.config.b1)\n",
        "        updates_g       = lasagne.updates.adam(obj_g, params_g, self.config.lr, self.config.b1)\n",
        "        \n",
        "       \n",
        "\n",
        "        # ##\n",
        "        # # theano functions\n",
        "        TimePrint(\"Compiling the network...\\n\")\n",
        "        self.train_d    = theano.function([X.input_var, Z.input_var], obj_d, updates=updates_d, allow_input_downcast=True)\n",
        "        TimePrint(\"Discriminator done.\")\n",
        "        self.train_g    = theano.function([Z.input_var], obj_g, updates=updates_g, allow_input_downcast=True)\n",
        "        TimePrint(\"Generator done.\")\n",
        "        self.generate   = theano.function([Z.input_var], prediction_gen, allow_input_downcast=True)\n",
        "        TimePrint(\"generate function done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e8cT1oi4FIE",
        "outputId": "48c718a2-8804-47fa-ee6f-f5deff225bea"
      },
      "source": [
        "pip install --upgrade https://github.com/Lasagne/Lasagne/archive/master.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/Lasagne/Lasagne/archive/master.zip\n",
            "  Downloading https://github.com/Lasagne/Lasagne/archive/master.zip\n",
            "\u001b[K     | 231 kB 234 kB/s\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/site-packages (from Lasagne==0.2.dev1) (1.19.2)\n",
            "Building wheels for collected packages: Lasagne\n",
            "  Building wheel for Lasagne (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Lasagne: filename=Lasagne-0.2.dev1-py3-none-any.whl size=122798 sha256=76765f7fcdf3334e91a073d4655492c2e463bd4b77bab780e27402fefbb35bd8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rho3n_0s/wheels/b6/a5/97/c657632d2b7fcff539623ea56996e09ec3c83c871e25a62cc5\n",
            "Successfully built Lasagne\n",
            "Installing collected packages: Lasagne\n",
            "Successfully installed Lasagne-0.2.dev1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "VhfKQlyE4Io4",
        "outputId": "4b4feadf-583f-4809-e31f-e59f5eb5e7d7"
      },
      "source": [
        "if __name__==\"__main__\":   \n",
        "    psgan        = PSGAN()\n",
        "    c = psgan.config           \n",
        "    c.print_info()\n",
        "    ##\n",
        "    # sample used just for visualisation\n",
        "    z_sample        = sample_noise_tensor(c,1,c.zx_sample,c.zx_sample_quilt)\n",
        "    epoch           = 0\n",
        "    tot_iter        = 0\n",
        "    gd_cost = []\n",
        "\n",
        "    while epoch < c.epoch_count:\n",
        "        epoch       += 1\n",
        "        print(\"Epoch %d\" % epoch)\n",
        "\n",
        "        Gcost = []\n",
        "        Dcost = []\n",
        "\n",
        "        iters = c.epoch_iters / c.batch_size\n",
        "        for it, samples in enumerate(tqdm(c.data_iter(), total=iters)):\n",
        "            if it >= iters:\n",
        "                break\n",
        "            tot_iter+=1\n",
        "\n",
        "            # random samples for training\n",
        "            Znp = sample_noise_tensor(c,c.batch_size,c.zx) \n",
        "\n",
        "            if tot_iter % (c.k+1) == 0:\n",
        "                cost = psgan.train_g(Znp)\n",
        "                Gcost.append(cost)\n",
        "            else:\n",
        "                cost = psgan.train_d(samples,Znp)\n",
        "                Dcost.append(cost)\n",
        "\n",
        "        print(\"Gcost=\", np.mean(Gcost), \"  Dcost=\", np.mean(Dcost))\n",
        "        gd_cost.append([np.mean(Gcost), np.mean(Dcost)])\n",
        "        \n",
        "        slist = []\n",
        "        for img in samples:\n",
        "            slist +=[img]\n",
        "        img = np.concatenate(slist,axis=2)        \n",
        "        # save_tensor(img, 'samples/minibatchTrue_%s_epoch%d.jpg' % (c.save_name,epoch))\n",
        "\n",
        "        samples =  psgan.generate(Znp)\n",
        "        slist = []\n",
        "        for img in samples:\n",
        "            slist +=[img]\n",
        "        img = np.concatenate(slist,axis=2)\n",
        "        # save_tensor(img, 'samples/minibatchGen_%s_epoch%d.jpg' % (c.save_name,epoch))\n",
        "\n",
        "        data = psgan.generate(z_sample)\n",
        "\n",
        "        save_tensor(data[0], 'samples/largesample%s_epoch%d_%f_%f.jpg' % (c.save_name,epoch,np.mean(Gcost),np.mean(Dcost)))\n",
        "        psgan.save('models/%s_epoch%d.psgan'%(c.save_name,epoch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling the network...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Discriminator done.\n",
            " (took  76.34541583061218 s)\n",
            "Generator done.\n",
            " (took  23.48599076271057 s)\n",
            "generate function done.\n",
            " (took  7.720543384552002 s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/500.0 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learning and generating samples from zx  2 , which yields images of size npx  33\n",
            "Producing samples from zx_sample  32 , which yields images of size npx  993\n",
            "Saving samples and model data to file  ulos1_filters64_npx33_5gL_5dL_60Global_3Periodic_FalseAffine_30Local\n",
            "Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-affa4c3794a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_iters\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-d92c680bd577>\u001b[0m in \u001b[0;36mget_texture_iter\u001b[0;34m(folder, npx, batch_size, filter, mirror)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mHW\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mnpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mimTex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/data/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RurwazNy4O2l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPJLtvu74p8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "8d7755f5-9683-4ff8-abb8-5747c9f97771"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hImK41d040wy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}